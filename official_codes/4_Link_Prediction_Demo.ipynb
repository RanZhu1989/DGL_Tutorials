{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda\\envs\\torch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "\n",
    "import dgl\n",
    "import dgl.data\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "dataset = dgl.data.CoraGraphDataset()\n",
    "g = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "训练集边数：测试集边数 = 9:1\n",
    "正样本：所有实际存在的边中随机选取90%作为训练集，剩下的10%作为测试集\n",
    "负样本：所有不存在的边中随机采样与正样本训练集/测试集相同数量的边\n",
    "'''\n",
    "u, v = g.edges()\n",
    "\n",
    "eids = np.arange(g.num_edges())\n",
    "eids = np.random.permutation(eids) #NOTE: shuffle\n",
    "\n",
    "test_size = int(len(eids) * 0.1)\n",
    "train_size = g.num_edges() - test_size\n",
    "\n",
    "'''\n",
    "从边中选取正样本边的起点和终点\n",
    "'''\n",
    "\n",
    "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
    "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
    "\n",
    "# Find all negative edges and split them for training and testing\n",
    "'''\n",
    "产生负样本，即不存在的边\n",
    "随机选取负样本边的起点和终点\n",
    "'''\n",
    "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
    "adj_neg = 1 - adj.todense() - np.eye(g.num_nodes())\n",
    "neg_u, neg_v = np.where(adj_neg != 0)\n",
    "\n",
    "neg_eids = np.random.choice(len(neg_u), g.num_edges())\n",
    "test_neg_u, test_neg_v = (\n",
    "    neg_u[neg_eids[:test_size]],\n",
    "    neg_v[neg_eids[:test_size]],\n",
    ")\n",
    "train_neg_u, train_neg_v = (\n",
    "    neg_u[neg_eids[test_size:]],\n",
    "    neg_v[neg_eids[test_size:]],\n",
    ")\n",
    "\n",
    "# NOTE: 从训练的图中移除测试集的边\n",
    "train_g = dgl.remove_edges(g,eids[:test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务描述：\n",
    "各节点通过图神经网络训练学习一个嵌入表示$h_{v}$, 然后训练一个函数$f(h_{v},h_{u})$来预测节点$u,v$之间存在边的概率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "节点学习一个嵌入表示\n",
    "'''\n",
    "\n",
    "from dgl.nn import SAGEConv\n",
    "\n",
    "\n",
    "# ----------- 2. create model -------------- #\n",
    "# build a two-layer GraphSAGE model\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, \"mean\")\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, \"mean\")\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测边是否存在的概率需要一个节点对，这个节点对可以看作是原图中的一条边，这条边的属性是由两端节点的属性计算得到。\n",
    "- 1. 在Train_Graph中训练图神经网络，得到节点的嵌入表示$h_{v}$。\n",
    "- 2. *计算* Train_Positive_Graph & Train_Negative_Graph中的边的嵌入表示, 获得损失函数。\n",
    "- 3. *测试* Test_Graph中的边的嵌入表示, 预测边是否存在。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "构建训练图和测试图\n",
    "'''\n",
    "\n",
    "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.num_nodes()) # 正图\n",
    "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.num_nodes()) # 负图\n",
    "\n",
    "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.num_nodes())\n",
    "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.num_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "用上面创建的图来计算边上的节点特征\n",
    "第1种方法: 将两端的节点特征点乘获得一个scalar特征\n",
    "- 先把特征赋值到图上\n",
    "- 用apply_edges函数计算边上的特征\n",
    "'''\n",
    "\n",
    "import dgl.function as fn\n",
    "\n",
    "\n",
    "class DotPredictor(nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata[\"h\"] = h\n",
    "            # Compute a new edge feature named 'score' by a dot-product between the\n",
    "            # source node feature 'h' and destination node feature 'h'.\n",
    "            g.apply_edges(fn.u_dot_v(\"h\", \"h\", \"score\"))\n",
    "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
    "            return g.edata[\"score\"][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "第2种方法: 将两端的节点特征拼接后通过一个MLP获得一个scalar特征\n",
    "- 先把特征赋值到图上\n",
    "- 用apply_edges函数计算边上的特征\n",
    "'''\n",
    "\n",
    "class MLPPredictor(nn.Module):\n",
    "    '''\n",
    "    Input: 所有节点的特征h\n",
    "    Output: 所有边的特征score\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, h_feats):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
    "        self.W2 = nn.Linear(h_feats, 1)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        \"\"\"\n",
    "        Computes a scalar score for each edge of the given graph.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        edges :\n",
    "            Has three members ``src``, ``dst`` and ``data``, each of\n",
    "            which is a dictionary representing the features of the\n",
    "            source nodes, the destination nodes, and the edges\n",
    "            themselves.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary of new edge features.\n",
    "        \"\"\"\n",
    "        h = torch.cat([edges.src[\"h\"], edges.dst[\"h\"]], 1)\n",
    "        return {\"score\": self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        '''\n",
    "        先给图赋值，再应用apply_edges函数对所有边进行计算\n",
    "        '''\n",
    "        with g.local_scope():\n",
    "            g.ndata[\"h\"] = h\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            return g.edata[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "实例化模型和预测器，并计算损失\n",
    "'''\n",
    "\n",
    "model = GraphSAGE(train_g.ndata[\"feat\"].shape[1], 16)\n",
    "# You can replace DotPredictor with MLPPredictor.\n",
    "pred = MLPPredictor(16)\n",
    "# pred = DotPredictor()\n",
    "\n",
    "\n",
    "def compute_loss(pos_score, neg_score):\n",
    "    # 正负样本及对应的标签concat，计算二分类交叉熵。\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
    "    ) # 正样本标签为1，负样本标签为0\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "#NOTE: 注意需要import sklearn中的roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    # 计算正负样本的roc_auc_score\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
    "    ).numpy()\n",
    "    return roc_auc_score(labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 0.7010293006896973\n",
      "In epoch 5, loss: 0.6924521923065186\n",
      "In epoch 10, loss: 0.6872186660766602\n",
      "In epoch 15, loss: 0.674706757068634\n",
      "In epoch 20, loss: 0.6486778259277344\n",
      "In epoch 25, loss: 0.6004092693328857\n",
      "In epoch 30, loss: 0.5699384808540344\n",
      "In epoch 35, loss: 0.5552774667739868\n",
      "In epoch 40, loss: 0.5337749123573303\n",
      "In epoch 45, loss: 0.5180059671401978\n",
      "In epoch 50, loss: 0.500512957572937\n",
      "In epoch 55, loss: 0.4778256416320801\n",
      "In epoch 60, loss: 0.44953662157058716\n",
      "In epoch 65, loss: 0.40838900208473206\n",
      "In epoch 70, loss: 0.3526500165462494\n",
      "In epoch 75, loss: 0.2958819568157196\n",
      "In epoch 80, loss: 0.2588243782520294\n",
      "In epoch 85, loss: 0.23327195644378662\n",
      "In epoch 90, loss: 0.2113390564918518\n",
      "In epoch 95, loss: 0.19299021363258362\n",
      "AUC 0.8264046180454167\n"
     ]
    }
   ],
   "source": [
    "# ----------- 3. set up loss and optimizer -------------- #\n",
    "# in this case, loss will in training loop\n",
    "optimizer = torch.optim.Adam(\n",
    "    itertools.chain(model.parameters(), pred.parameters()), lr=0.01\n",
    ") #NOTE: 同时训练时避免使用多个优化器\n",
    "\n",
    "# ----------- 4. training -------------------------------- #\n",
    "'''\n",
    "训练流程：\n",
    "- 在train_g上计算节点特征\n",
    "- 在train_pos_g和train_neg_g上计算边的Score\n",
    "- 计算loss\n",
    "- Backward and optimize\n",
    "\n",
    "'''\n",
    "all_logits = []\n",
    "for e in range(100):\n",
    "    # forward\n",
    "    h = model(train_g, train_g.ndata[\"feat\"])\n",
    "    pos_score = pred(train_pos_g, h)\n",
    "    neg_score = pred(train_neg_g, h)\n",
    "    loss = compute_loss(pos_score, neg_score)\n",
    "\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if e % 5 == 0:\n",
    "        print(\"In epoch {}, loss: {}\".format(e, loss))\n",
    "\n",
    "# ----------- 5. check results ------------------------ #\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    pos_score = pred(test_pos_g, h)\n",
    "    neg_score = pred(test_neg_g, h)\n",
    "    print(\"AUC\", compute_auc(pos_score, neg_score))\n",
    "\n",
    "\n",
    "# Thumbnail credits: Link Prediction with Neo4j, Mark Needham\n",
    "# sphinx_gallery_thumbnail_path = '_static/blitz_4_link_predict.png'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
